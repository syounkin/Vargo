<link href="http://kevinburke.bitbucket.org/markdowncss/markdown.css" rel="stylesheet"></link>
<link href="http://www.biostat.wisc.edu/~syounkin/markdown_modified.css" rel="stylesheet"></link>

# DataScraper

## Load Libraries

```{r DataScraper, message=FALSE}
library("DataScraper")
library("XML")
require("parallel")
getwd()
date()
```

### Import Assessor Property Information for Madison

```{r input, eval = TRUE}
prop_info <- read.csv(file = "./data/energyTables/Assessor_Property_Information.csv", header=T, sep = ",", stringsAsFactors = FALSE)
```

###  Expand Address field to be multiple fields

Here we use a function written by Tewdard to parse the property file.

```{r expand}
prop_info_expandedAddress <- expand_address(prop_info$Address)
prop_info_expandedAddress <- cbind(prop_info, prop_info_expandedAddress)
```

###  Keep only residential, single unit, single family properties

```{r non-residential}
prop_info_expandedAddress <- subset(prop_info_expandedAddress, Property.Class == "Residential")
prop_info_expandedAddress <- subset(prop_info_expandedAddress, Dwelling.Units == 1)
prop_info_expandedAddress <- subset(prop_info_expandedAddress, Property.Use == "Single family")
```

### Loop through addresses and pull html tables from MGE web-page

```{r mge}
date()

Active_Address_List <- prop_info_expandedAddress
root_url <- "http://www.mge.com/customer-service/home/average-use-cost/results.htm?"
timestamp <- gsub("\\s|:","-",Sys.time())
energy.table.list <- list()

## n <- 10
## for( i in 1:n ){
for( i in 1:nrow(Active_Address_List) ){

  house_number<-Active_Address_List$Address_Num[i]   # set house number
  street_direction<-Active_Address_List$Address_StreetDirection[i]   #set sd
  street_name<-Active_Address_List$Address_StreetName[i]   #set street name
  street_suffix<-Active_Address_List$Address_StreetType[i]   #set street suffix/Type
  apartment_unit<-Active_Address_List$Address_UnitNum[i]   #set au
  city<-"Madison"
  
  full_mge_url<-paste( root_url,
                      "hn=",house_number,
                      "&sd=",street_direction,
                      "&sn=",street_name,
                      "&ss=",street_suffix,
                      "&au=",apartment_unit,
                      "&c=",city,sep=""
                      )

  energy_table <- readHTMLTable(full_mge_url,as.data.frame=F)

  energy.table.list <- c(energy.table.list, energy_table)

}

## names(energy.table.list) <- as.character(Active_Address_List$Parcel)[1:n]
names(energy.table.list) <- as.character(Active_Address_List$Parcel)

saveRDS(energy.table.list, file = paste("./data/energyTables/energyTableList-", timestamp, ".rds", sep = ""))
date()
```

### Parse data object with multiple cores

Here we take the raw data from the web-server and transform it to a
more manageable form.  We do so using mclapply and take advatage of
multiple cores.

```{r test2, error = FALSE, warning = FALSE}
parsedEnergyList <- mclapply(energy.table.list, parseEnergyTable,mc.cores = 8)
```

### Failures have NULL entries (with length equal to zero)

Calculate the success rate.

```{r failed}
failureIndex <- which(unlist(lapply(parsedEnergyList,function(x)length(x)==0)))
1 - length(failureIndex)/length(parsedEnergyList)
```

### Write parsed data to file

Now we reshape the parsed enegry list to a data frame and write the
data to a ".csv" file.

```{r energyFile}
energy.df <- reshapeEnergyTableList(parsedEnergyList, filename = paste("./data/energyTables/energyFile-",timestamp,".csv",sep=""))
```

### Merge results to property data with "parcel" number

It's easy to merge the energy usage data with the property info.

```{r merge}
dataFull <- merge(energy.df, prop_info, by.x="parcel", by.y="Parcel")
```

### Session Info

What version of R and R packages were used?  We list that here.

```{r session}
sessionInfo()
```
